{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HyperasOnColabExample.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FYdi32_ixNJY","colab_type":"code","outputId":"4841c38a-7fe0-4653-94cd-dfd29d43b686","executionInfo":{"status":"ok","timestamp":1543762611763,"user_tz":-60,"elapsed":10571,"user":{"displayName":"Nils Schlüter","photoUrl":"","userId":"08551284009659866560"}},"colab":{"base_uri":"https://localhost:8080/","height":1428}},"source":["!pip install hyperas\n","!pip install hyperopt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting hyperas\n","  Downloading https://files.pythonhosted.org/packages/54/72/5533b6bf9b47dc33685c3e62c391d6eab5785a648a5ffa841e240a3db3fe/hyperas-0.4.tar.gz\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n","Collecting hyperopt (from hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/9f/f6324af3fc43f352e568b5850695c30ed7dd14af06a94f97953ff9187569/hyperopt-0.1.1-py3-none-any.whl (117kB)\n","\u001b[K    100% |████████████████████████████████| 122kB 9.9MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.2.3)\n","Collecting jupyter (from hyperas)\n","  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.4.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.11.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.6)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.14.6)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n","Collecting pymongo (from hyperopt->hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n","\u001b[K    100% |████████████████████████████████| 409kB 16.2MB/s \n","\u001b[?25hCollecting jupyter-console (from jupyter->hyperas)\n","  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n","Collecting ipywidgets (from jupyter->hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n","\u001b[K    100% |████████████████████████████████| 112kB 29.1MB/s \n","\u001b[?25hCollecting qtconsole (from jupyter->hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/7a/8aefbc0ed078dec7951ac9a06dcd1869243ecd7bcbce26fa47bf5e469a8f/qtconsole-4.4.3-py2.py3-none-any.whl (113kB)\n","\u001b[K    100% |████████████████████████████████| 122kB 36.0MB/s \n","\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n","Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.0.2)\n","Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.5.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.3.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.2.3)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/e6/adb3be5576f5d27c6faa33f1e9fea8fe5dbd9351db12148de948507e352c/prompt_toolkit-2.0.7-py3-none-any.whl (338kB)\n","\u001b[K    100% |████████████████████████████████| 348kB 27.2MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n","Collecting widgetsnbextension~=3.4.0 (from ipywidgets->jupyter->hyperas)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n","\u001b[K    100% |████████████████████████████████| 2.2MB 12.5MB/s \n","\u001b[?25hRequirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->hyperas) (1.1.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (17.0.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.5.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.6.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (40.6.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n","Building wheels for collected packages: hyperas\n","  Running setup.py bdist_wheel for hyperas ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/38/3f/27826f57fae60ef788ceb47e2c649590ab8af31f42075325d2\n","Successfully built hyperas\n","\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.7 which is incompatible.\u001b[0m\n","Installing collected packages: pymongo, hyperopt, prompt-toolkit, jupyter-console, widgetsnbextension, ipywidgets, qtconsole, jupyter, hyperas\n","  Found existing installation: prompt-toolkit 1.0.15\n","    Uninstalling prompt-toolkit-1.0.15:\n","      Successfully uninstalled prompt-toolkit-1.0.15\n","Successfully installed hyperas-0.4 hyperopt-0.1.1 ipywidgets-7.4.2 jupyter-1.0.0 jupyter-console-6.0.0 prompt-toolkit-2.0.7 pymongo-3.7.2 qtconsole-4.4.3 widgetsnbextension-3.4.2\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.7.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.1.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i3rEszUh5TuI","colab_type":"code","outputId":"efbb53a3-4f77-4e08-a966-64d6e53d2d75","executionInfo":{"status":"ok","timestamp":1543762652982,"user_tz":-60,"elapsed":2400,"user":{"displayName":"Nils Schlüter","photoUrl":"","userId":"08551284009659866560"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import print_function\n","from hyperopt import Trials, STATUS_OK, tpe\n","from hyperas import optim\n","from hyperas.distributions import choice, uniform\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.datasets import mnist\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FdFjtmrj5Gfz","colab_type":"code","colab":{}},"source":["def data():\n","    '''\n","    Data providing function:\n","    This function is separated from model() so that hyperopt\n","    won't reload data for each evaluation run.\n","    '''\n","    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","    X_train = X_train.reshape(60000, 784)\n","    X_test = X_test.reshape(10000, 784)\n","    X_train = X_train.astype('float32')\n","    X_test = X_test.astype('float32')\n","    X_train /= 255\n","    X_test /= 255\n","    nb_classes = 10\n","    Y_train = np_utils.to_categorical(y_train, nb_classes)\n","    Y_test = np_utils.to_categorical(y_test, nb_classes)\n","    return X_train, Y_train, X_test, Y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIygRZ6f5UkF","colab_type":"code","colab":{}},"source":["def model(X_train, Y_train, X_test, Y_test):\n","    '''\n","    Model providing function:\n","    Create Keras model with double curly brackets dropped-in as needed.\n","    Return value has to be a valid python dictionary with two customary keys:\n","        - loss: Specify a numeric evaluation metric to be minimized\n","        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n","    The last one is optional, though recommended, namely:\n","        - model: specify the model just created so that we can later use it again.\n","    '''\n","    model = Sequential()\n","    model.add(Dense(512, input_shape=(784,)))\n","    model.add(Activation('relu'))\n","    model.add(Dropout({{uniform(0, 1)}}))\n","    model.add(Dense({{choice([256, 512, 1024])}}))\n","    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n","    model.add(Dropout({{uniform(0, 1)}}))\n","\n","    # If we choose 'four', add an additional fourth layer\n","    if {{choice(['three', 'four'])}} == 'four':\n","        model.add(Dense(100))\n","        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n","        model.add(Activation('relu'))\n","\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n","                  metrics=['accuracy'])\n","\n","    model.fit(X_train, Y_train,\n","              batch_size={{choice([64, 128])}},\n","              nb_epoch=1,\n","              verbose=2,\n","              validation_data=(X_test, Y_test))\n","    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n","    print('Test accuracy:', acc)\n","    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjlatkWq5Wab","colab_type":"code","colab":{}},"source":["# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n","# Install the PyDrive wrapper & import libraries.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Copy/download the file\n","fid = drive.ListFile({'q':\"title='HyperasOnColabExample.ipynb'\"}).GetList()[0]['id']\n","f = drive.CreateFile({'id': fid})\n","f.GetContentFile('HyperasOnColabExample.ipynb')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdo3mScvBHF4","colab_type":"code","outputId":"61772694-737a-4d27-c5c8-75d8ad7300a2","executionInfo":{"status":"ok","timestamp":1543762732173,"user_tz":-60,"elapsed":76494,"user":{"displayName":"Nils Schlüter","photoUrl":"","userId":"08551284009659866560"}},"colab":{"base_uri":"https://localhost:8080/","height":3077}},"source":["best_run, best_model = optim.minimize(model=model,\n","                                          data=data,\n","                                          max_evals=10,\n","                                          algo=tpe.suggest,\n","                                          notebook_name='HyperasOnColabExample', # This is important!\n","                                          trials=Trials())"],"execution_count":0,"outputs":[{"output_type":"stream","text":[">>> Imports:\n","#coding=utf-8\n","\n","from __future__ import print_function\n","\n","try:\n","    from hyperopt import Trials, STATUS_OK, tpe\n","except:\n","    pass\n","\n","try:\n","    from hyperas import optim\n","except:\n","    pass\n","\n","try:\n","    from hyperas.distributions import choice, uniform\n","except:\n","    pass\n","\n","try:\n","    from keras.models import Sequential\n","except:\n","    pass\n","\n","try:\n","    from keras.layers.core import Dense, Dropout, Activation\n","except:\n","    pass\n","\n","try:\n","    from keras.datasets import mnist\n","except:\n","    pass\n","\n","try:\n","    from keras.utils import np_utils\n","except:\n","    pass\n","\n","try:\n","    from pydrive.auth import GoogleAuth\n","except:\n","    pass\n","\n","try:\n","    from pydrive.drive import GoogleDrive\n","except:\n","    pass\n","\n","try:\n","    from google.colab import auth\n","except:\n","    pass\n","\n","try:\n","    from oauth2client.client import GoogleCredentials\n","except:\n","    pass\n","\n",">>> Hyperas search space:\n","\n","def get_space():\n","    return {\n","        'Dropout': hp.uniform('Dropout', 0, 1),\n","        'Dense': hp.choice('Dense', [256, 512, 1024]),\n","        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n","        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n","        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n","        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n","        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n","        'batch_size': hp.choice('batch_size', [64, 128]),\n","    }\n","\n",">>> Data\n","  1: \n","  2: '''\n","  3: Data providing function:\n","  4: This function is separated from model() so that hyperopt\n","  5: won't reload data for each evaluation run.\n","  6: '''\n","  7: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","  8: X_train = X_train.reshape(60000, 784)\n","  9: X_test = X_test.reshape(10000, 784)\n"," 10: X_train = X_train.astype('float32')\n"," 11: X_test = X_test.astype('float32')\n"," 12: X_train /= 255\n"," 13: X_test /= 255\n"," 14: nb_classes = 10\n"," 15: Y_train = np_utils.to_categorical(y_train, nb_classes)\n"," 16: Y_test = np_utils.to_categorical(y_test, nb_classes)\n"," 17: \n"," 18: \n"," 19: \n",">>> Resulting replaced keras model:\n","\n","   1: def keras_fmin_fnct(space):\n","   2: \n","   3:     '''\n","   4:     Model providing function:\n","   5:     Create Keras model with double curly brackets dropped-in as needed.\n","   6:     Return value has to be a valid python dictionary with two customary keys:\n","   7:         - loss: Specify a numeric evaluation metric to be minimized\n","   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n","   9:     The last one is optional, though recommended, namely:\n","  10:         - model: specify the model just created so that we can later use it again.\n","  11:     '''\n","  12:     model = Sequential()\n","  13:     model.add(Dense(512, input_shape=(784,)))\n","  14:     model.add(Activation('relu'))\n","  15:     model.add(Dropout(space['Dropout']))\n","  16:     model.add(Dense(space['Dense']))\n","  17:     model.add(Activation(space['Activation']))\n","  18:     model.add(Dropout(space['Dropout_1']))\n","  19: \n","  20:     # If we choose 'four', add an additional fourth layer\n","  21:     if space['Dropout_2'] == 'four':\n","  22:         model.add(Dense(100))\n","  23:         model.add(space['add'])\n","  24:         model.add(Activation('relu'))\n","  25: \n","  26:     model.add(Dense(10))\n","  27:     model.add(Activation('softmax'))\n","  28: \n","  29:     model.compile(loss='categorical_crossentropy',\n","  30:                   optimizer=space['optimizer'],\n","  31:                   metrics=['accuracy'])\n","  32: \n","  33:     model.fit(X_train, Y_train,\n","  34:               batch_size=space['batch_size'],\n","  35:               nb_epoch=1,\n","  36:               verbose=2,\n","  37:               validation_data=(X_test, Y_test))\n","  38:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n","  39:     print('Test accuracy:', acc)\n","  40:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n","  41: \n","Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/content/temp_model.py:115: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 5s - loss: 1.6471 - acc: 0.4509 - val_loss: 0.7436 - val_acc: 0.8371\n","Test accuracy: 0.8371\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 6s - loss: 2.1491 - acc: 0.3022 - val_loss: 0.6901 - val_acc: 0.8151\n","Test accuracy: 0.8151\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 6s - loss: 1.9763 - acc: 0.2981 - val_loss: 0.7141 - val_acc: 0.8806\n","Test accuracy: 0.8806\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 4s - loss: 0.7199 - acc: 0.7695 - val_loss: 0.1967 - val_acc: 0.9387\n","Test accuracy: 0.9387\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 4s - loss: 0.4887 - acc: 0.8522 - val_loss: 0.1607 - val_acc: 0.9493\n","Test accuracy: 0.9493\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 3s - loss: 2.7203 - acc: 0.1112 - val_loss: 2.1550 - val_acc: 0.5827\n","Test accuracy: 0.5827\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 3s - loss: 0.2794 - acc: 0.9141 - val_loss: 0.1323 - val_acc: 0.9594\n","Test accuracy: 0.9594\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 3s - loss: 2.1919 - acc: 0.2076 - val_loss: 1.8377 - val_acc: 0.6396\n","Test accuracy: 0.6396\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 4s - loss: 0.4639 - acc: 0.8528 - val_loss: 0.1851 - val_acc: 0.9426\n","Test accuracy: 0.9426\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/1\n"," - 8s - loss: 0.2989 - acc: 0.9095 - val_loss: 0.1244 - val_acc: 0.9622\n","Test accuracy: 0.9622\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UaEviY3SbLlB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}